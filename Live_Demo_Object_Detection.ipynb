{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Live_Demo_Object_Detection.ipynb","provenance":[],"collapsed_sections":["NJQE42EhDnlM","_lg4cKQjD0Tn"],"machine_shape":"hm","toc_visible":true,"mount_file_id":"18tUYpuCDSTuqDysvfxEqZ_TUZiZMFaUd","authorship_tag":"ABX9TyPdmxzgezHQl+2MJryksNi3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["**Live Demo of Object Detection using Google Colab Webcam**\n"],"metadata":{"id":"VwscZkPRD3Zx"}},{"cell_type":"markdown","source":["# Mount Drive"],"metadata":{"id":"NJQE42EhDnlM"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jrs8mTnnQItd","executionInfo":{"status":"ok","timestamp":1651427303095,"user_tz":-480,"elapsed":20658,"user":{"displayName":"Abby Abby","userId":"18409237732645261754"}},"outputId":"ca120b1c-39c0-4902-ff77-ae98e82d993c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["# Change Directory"],"metadata":{"id":"jpeEBsX0DtgR"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Colab Notebooks/objectdetection"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1_YmVs8HQJSu","executionInfo":{"status":"ok","timestamp":1651427309598,"user_tz":-480,"elapsed":550,"user":{"displayName":"Abby Abby","userId":"18409237732645261754"}},"outputId":"2836cf68-aa4e-4193-abd0-0b1d07e703f6"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/objectdetection\n"]}]},{"cell_type":"markdown","source":["# Install Requirements"],"metadata":{"id":"_lg4cKQjD0Tn"}},{"cell_type":"code","source":["!pip install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u_D1uEIUQxJm","executionInfo":{"status":"ok","timestamp":1651427329301,"user_tz":-480,"elapsed":16427,"user":{"displayName":"Abby Abby","userId":"18409237732645261754"}},"outputId":"1385c374-a42f-473e-e2b0-09efb7d38ba0"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: Cython==0.29.28 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (0.29.28)\n","Requirement already satisfied: pycocotools==2.0.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (2.0.4)\n","Collecting wandb\n","  Downloading wandb-0.12.15-py2.py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 4.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.21.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (3.2.2)\n","Requirement already satisfied: pathlib==1.0.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.0.1)\n","Requirement already satisfied: Pillow==7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (7.1.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (1.11.0+cu113)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (0.12.0+cu113)\n","Collecting Image\n","  Downloading image-1.5.33.tar.gz (15 kB)\n","Collecting pytorch-lightning\n","  Downloading pytorch_lightning-1.6.2-py3-none-any.whl (582 kB)\n","\u001b[K     |████████████████████████████████| 582 kB 74.2 MB/s \n","\u001b[?25hCollecting torchmetrics\n","  Downloading torchmetrics-0.8.1-py3-none-any.whl (408 kB)\n","\u001b[K     |████████████████████████████████| 408 kB 85.3 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.4.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (3.0.8)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->-r requirements.txt (line 5)) (4.2.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->-r requirements.txt (line 5)) (1.15.0)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 68.7 MB/s \n","\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 3)) (2.3)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting setproctitle\n","  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 3)) (2.23.0)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.5.10-py2.py3-none-any.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 60.7 MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 3)) (3.13)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 3)) (5.4.8)\n","Collecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n","Collecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 3)) (7.1.2)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 3)) (3.17.3)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n","\u001b[?25hCollecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 3)) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 3)) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 3)) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 3)) (3.0.4)\n","Collecting django\n","  Downloading Django-3.2.13-py3-none-any.whl (7.9 MB)\n","\u001b[K     |████████████████████████████████| 7.9 MB 15.8 MB/s \n","\u001b[?25hCollecting pyDeprecate<0.4.0,>=0.3.1\n","  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n","Collecting PyYAML\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 86.3 MB/s \n","\u001b[?25hCollecting fsspec[http]!=2021.06.0,>=2021.05.0\n","  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n","\u001b[K     |████████████████████████████████| 136 kB 89.5 MB/s \n","\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning->-r requirements.txt (line 11)) (2.8.0)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning->-r requirements.txt (line 11)) (4.64.0)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning->-r requirements.txt (line 11)) (21.3)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 75.3 MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 11)) (1.0.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 11)) (1.8.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 11)) (1.35.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 11)) (57.4.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 11)) (1.0.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 11)) (0.37.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 11)) (1.44.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 11)) (0.4.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 11)) (0.6.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 11)) (3.3.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 11)) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 11)) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 11)) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 11)) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 11)) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 11)) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 11)) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 11)) (3.2.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->-r requirements.txt (line 11)) (21.4.0)\n","Collecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 78.6 MB/s \n","\u001b[?25hCollecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 4.6 MB/s \n","\u001b[?25hCollecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 98.2 MB/s \n","\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->-r requirements.txt (line 11)) (2.0.12)\n","Collecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: sqlparse>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from django->Image->-r requirements.txt (line 10)) (0.4.2)\n","Collecting asgiref<4,>=3.3.2\n","  Downloading asgiref-3.5.1-py3-none-any.whl (22 kB)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from django->Image->-r requirements.txt (line 10)) (2022.1)\n","Building wheels for collected packages: Image, pathtools\n","  Building wheel for Image (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for Image: filename=image-1.5.33-py2.py3-none-any.whl size=19496 sha256=daf16c65855ff70187fa5cc5803ea71aeb1a27aab6d65e7724472c8310670701\n","  Stored in directory: /root/.cache/pip/wheels/56/88/e6/897194cfe8c08a8b9afd881d3bf53d102e13fa39607d721383\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=88c9dd25a39166b612cde2fd9ccba363526267b260d5f02f6118b14f2e37570c\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built Image pathtools\n","Installing collected packages: multidict, frozenlist, yarl, smmap, asynctest, async-timeout, aiosignal, pyDeprecate, gitdb, fsspec, asgiref, aiohttp, torchmetrics, shortuuid, setproctitle, sentry-sdk, PyYAML, pathtools, GitPython, docker-pycreds, django, wandb, pytorch-lightning, Image\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed GitPython-3.1.27 Image-1.5.33 PyYAML-6.0 aiohttp-3.8.1 aiosignal-1.2.0 asgiref-3.5.1 async-timeout-4.0.2 asynctest-0.13.0 django-3.2.13 docker-pycreds-0.4.0 frozenlist-1.3.0 fsspec-2022.3.0 gitdb-4.0.9 multidict-6.0.2 pathtools-0.1.2 pyDeprecate-0.3.2 pytorch-lightning-1.6.2 sentry-sdk-1.5.10 setproctitle-1.2.3 shortuuid-1.0.8 smmap-5.0.0 torchmetrics-0.8.1 wandb-0.12.15 yarl-1.7.2\n"]}]},{"cell_type":"markdown","source":["# Program"],"metadata":{"id":"Zfwhu_kkEVnP"}},{"cell_type":"code","source":["#import functions \n","import os\n","import pathlib\n","import cv2\n","import PIL\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import io\n","import scipy.misc\n","import numpy as np\n","from six import BytesIO\n","from PIL import Image, ImageDraw, ImageFont\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","from IPython.display import display, Javascript\n","from google.colab.output import eval_js\n","from base64 import b64decode, b64encode\n","import io\n","import html\n","import time\n","import torch\n","import argparse\n","#import detect_utils\n","import torchvision.transforms as transforms\n","import cv2\n","import numpy as np\n","import labelutils\n","import matplotlib.pyplot as plt\n","import utils\n","import torchvision\n","import sys\n","import math\n","import time\n","import datetime\n","import os\n","from LitDrinksModel import LitDrinksModel\n","import torchvision\n","import cv2\n","#import detect_utils\n","import config\n","import label_utils\n","from google.colab.patches import cv2_imshow\n"],"metadata":{"id":"92qS-bRjEbyo","executionInfo":{"status":"ok","timestamp":1651427741263,"user_tz":-480,"elapsed":611,"user":{"displayName":"Abby Abby","userId":"18409237732645261754"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# define the torchvision image transforms\n","normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                std=[0.229, 0.224, 0.225])\n","transform = transforms.Compose([transforms.ToTensor(),normalize])\n","\n","\n","\n","cur_dir = os.getcwd()\n","coco_names = config.params['classes']\n","\n","\n","\n","\n","# JavaScript to properly create our live video stream using our webcam as input\n","def video_stream():\n","  js = Javascript('''\n","    var video;\n","    var div = null;\n","    var stream;\n","    var captureCanvas;\n","    var imgElement;\n","    var labelElement;\n","    \n","    var pendingResolve = null;\n","    var shutdown = false;\n","    \n","    function removeDom() {\n","       stream.getVideoTracks()[0].stop();\n","       video.remove();\n","       div.remove();\n","       video = null;\n","       div = null;\n","       stream = null;\n","       imgElement = null;\n","       captureCanvas = null;\n","       labelElement = null;\n","    }\n","    \n","    function onAnimationFrame() {\n","      if (!shutdown) {\n","        window.requestAnimationFrame(onAnimationFrame);\n","      }\n","      if (pendingResolve) {\n","        var result = \"\";\n","        if (!shutdown) {\n","          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n","          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n","        }\n","        var lp = pendingResolve;\n","        pendingResolve = null;\n","        lp(result);\n","      }\n","    }\n","    \n","    async function createDom() {\n","      if (div !== null) {\n","        return stream;\n","      }\n","\n","      div = document.createElement('div');\n","      div.style.border = '2px solid black';\n","      div.style.padding = '3px';\n","      div.style.width = '100%';\n","      div.style.maxWidth = '600px';\n","      document.body.appendChild(div);\n","      \n","      const modelOut = document.createElement('div');\n","      modelOut.innerHTML = \"<span>Status:</span>\";\n","      labelElement = document.createElement('span');\n","      labelElement.innerText = 'No data';\n","      labelElement.style.fontWeight = 'bold';\n","      modelOut.appendChild(labelElement);\n","      div.appendChild(modelOut);\n","           \n","      video = document.createElement('video');\n","      video.style.display = 'block';\n","      video.width = div.clientWidth - 6;\n","      video.setAttribute('playsinline', '');\n","      video.onclick = () => { shutdown = true; };\n","      stream = await navigator.mediaDevices.getUserMedia(\n","          {video: { facingMode: \"environment\"}});\n","      div.appendChild(video);\n","\n","      imgElement = document.createElement('img');\n","      imgElement.style.position = 'absolute';\n","      imgElement.style.zIndex = 1;\n","      imgElement.onclick = () => { shutdown = true; };\n","      div.appendChild(imgElement);\n","      \n","      const instruction = document.createElement('div');\n","      instruction.innerHTML = \n","          '<span style=\"color: red; font-weight: bold;\">' +\n","          'When finished, click here or on the video to stop this demo</span>';\n","      div.appendChild(instruction);\n","      instruction.onclick = () => { shutdown = true; };\n","      \n","      video.srcObject = stream;\n","      await video.play();\n","\n","      captureCanvas = document.createElement('canvas');\n","      captureCanvas.width = 640; //video.videoWidth;\n","      captureCanvas.height = 480; //video.videoHeight;\n","      window.requestAnimationFrame(onAnimationFrame);\n","      \n","      return stream;\n","    }\n","    async function stream_frame(label, imgData) {\n","      if (shutdown) {\n","        removeDom();\n","        shutdown = false;\n","        return '';\n","      }\n","\n","      var preCreate = Date.now();\n","      stream = await createDom();\n","      \n","      var preShow = Date.now();\n","      if (label != \"\") {\n","        labelElement.innerHTML = label;\n","      }\n","            \n","      if (imgData != \"\") {\n","        var videoRect = video.getClientRects()[0];\n","        imgElement.style.top = videoRect.top + \"px\";\n","        imgElement.style.left = videoRect.left + \"px\";\n","        imgElement.style.width = videoRect.width + \"px\";\n","        imgElement.style.height = videoRect.height + \"px\";\n","        imgElement.src = imgData;\n","      }\n","      \n","      var preCapture = Date.now();\n","      var result = await new Promise(function(resolve, reject) {\n","        pendingResolve = resolve;\n","      });\n","      shutdown = false;\n","      \n","      return {'create': preShow - preCreate, \n","              'show': preCapture - preShow, \n","              'capture': Date.now() - preCapture,\n","              'img': result};\n","    }\n","    ''')\n","\n","  display(js)\n","  \n","def video_frame(label, bbox):\n","  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n","  return data\n","\n","# function to convert the JavaScript object into an OpenCV image\n","def js_to_image(js_reply):\n","  \"\"\"\n","  Params:\n","          js_reply: JavaScript object containing image from webcam\n","  Returns:\n","          img: OpenCV BGR image\n","  \"\"\"\n","  # decode base64 image\n","  image_bytes = b64decode(js_reply.split(',')[1])\n","  # convert bytes to numpy array\n","  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n","  # decode numpy array into OpenCV BGR image\n","  img = cv2.imdecode(jpg_as_np, flags=1)\n","\n","  return img\n","\n","# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n","def bbox_to_bytes(bbox_array):\n","  \"\"\"\n","  Params:\n","          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n","  Returns:\n","        bytes: Base64 image byte string\n","  \"\"\"\n","  # convert array into PIL image\n","  bbox_PIL = PIL.Image.fromarray(bbox_array) # numpy array into PIL image object\n","  iobuf = io.BytesIO()\n","  \n","  # format bbox into png for return\n","  bbox_PIL.save(iobuf, format='png')\n","\n","  # format return string\n","  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n","\n","  return bbox_bytes\n","\n","\n","\n","  \n","\n","def draw_boxes(boxes, classes, labels, image,scores):\n","    # read the image with OpenCV\n","    #image = np.array(image)\n","    \n","    class_names = classes\n","    rects = boxes   \n","    #print(class_names)\n","    font = cv2.FONT_HERSHEY_DUPLEX\n","    pos = (10,30)\n","    font_scale = 0.9\n","    font_color = (0, 0, 0)\n","    line_type = 1\n","    items = {}\n","    for i in range(len(scores)):\n","        rect = rects[i]\n","        x1 = rect[0]\n","        y1 = rect[1]\n","        x2 = rect[2]\n","        y2 = rect[3]\n","        #x2 = x1 + rect[2]\n","        #y2 = y1 + rect[3]\n","        x1 = int(x1)\n","        x2 = int(x2)\n","        y1 = int(y1)\n","        y2 = int(y2)\n","        name = class_names[i].split(\":\")[0]\n","        if name in items.keys():\n","            items[name] += 1\n","        else:\n","            items[name] = 1\n","        index = label_utils.class2index(name)\n","        color = label_utils.get_box_rgbcolor(index)\n","        cv2.rectangle(image, (x1, y1), (x2, y2), color, 3)\n","        # print(x1, y1, x2, y2, class_names[i])\n","        cv2.putText(image,\n","                    name,\n","                    (x1, y1-15),\n","                    font,\n","                    0.5,\n","                    color,\n","                    line_type)\n","    \n","\n","    count = len(items.keys())\n","    if count > 0:\n","        xmin = 10\n","        ymin = 10\n","        xmax = 220\n","        ymax = 40 + count * 30\n","        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (255, 255, 255), thickness=-1)\n","\n","        prices = config.params['prices']\n","        total = 0.0\n","        for key in items.keys():\n","            count = items[key]\n","            cost = count * prices[label_utils.class2index(key)]\n","            total += cost\n","            display = \"%0.2f :%dx %s\" % (cost, count, key)\n","            cv2.putText(image,\n","                        display,\n","                        (xmin + 10, ymin + 25),\n","                        font,\n","                        0.55,\n","                        (0, 0, 0),\n","                        1)\n","            ymin += 30\n","\n","        cv2.line(image, (xmin + 10, ymin), (xmax - 10, ymin), (0,0,0), 1)\n","\n","        display = \"P%0.2f Total\" % (total)\n","        cv2.putText(image,\n","                    display,\n","                    (xmin + 5, ymin + 25),\n","                    font,\n","                    0.75,\n","                    (0, 0, 0),\n","                    1)\n","\n","    #cv2_imshow( image)\n","\n","    return image\n","\n","\n","import itertools\n","\n","def run_inference_for_single_image(model, image, live_cam,device,detection_threshold):\n","    \n","    # convert image into numpy\n","    image = np.asarray(image)\n","    #print('Converted image into numpy type:', type(image))\n","    \n","    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n","    #input_tensor = tf.convert_to_tensor(image)\n","    input_tensor = transform(image).to(device)\n","    #print('Converted numpy into tensor format:', input_tensor)\n","    \n","    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n","    input_tensor = input_tensor[tf.newaxis,...]\n","    \n","    # Run inference\n","    if not live_cam:\n","      start_time = time.time()\n","      outputs = model(input_tensor)\n","      end_time = time.time()\n","      print(f\"Inference time: {np.ceil(end_time-start_time)} seconds per frame\")\n","\n","    #start_time = time.time()\n","    outputs = model(input_tensor)\n","    #end_time = time.time()\n","    #print(start_time-end_time)\n","    pred_scores = outputs[0]['scores'].detach().cpu().numpy()\n","    pred_scores = pred_scores[pred_scores >= detection_threshold]\n","    num_detections = len(pred_scores)\n","    #outputs = dict(itertools.islice(outputs.items(), num_detections))\n","    outputs[0]['labels'] = outputs[0]['labels'][0:num_detections]\n","    pred_classes = [coco_names[i] for i in outputs[0]['labels'].cpu().numpy()]\n","    # get score for all the predicted objects\n","    #pred_scores = outputs[0]['scores'].detach().cpu().numpy()\n","    # get all the predicted bounding boxes\n","    outputs[0]['boxes'] = outputs[0]['boxes'][0:num_detections]\n","    pred_bboxes = outputs[0]['boxes'].detach().cpu().numpy()\n","    # get boxes above the threshold score\n","    #print(pred_scores)\n","    boxes = pred_bboxes[pred_scores >= detection_threshold].astype(np.int32)\n","    pred_scores = pred_scores[pred_scores >= detection_threshold]\n","    \n","\n","    return boxes, pred_classes, outputs[0]['labels'] , pred_scores\n","        \n","\n","\n","\n","    #output_dict = model(input_tensor)\n","    #num_detections = int(output_dict.pop('num_detections')) # 300\n","\n","    # All outputs are batches tensors.\n","    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n","    # We're only interested in the first num_detections.\n","    \n","    #output_dict = {key: value[0, :num_detections].numpy()\n","     #              for key, value in output_dict.items()}\n","    \n","    #output_dict['num_detections'] = num_detections\n","\n","    # detection_classes should be ints.\n","    #output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n","    \n","\n","    #return output_dict\n","\n","def run_inference_video(model, video_path, live_cam):\n","  cap = cv2.VideoCapture(video_path)\n","  if cap.isOpened():\n","      width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","      height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","      res=(int(width), int(height))\n","\n","      # save detected video\n","      # Initialize our video writer\n","      fourcc = cv2.VideoWriter_fourcc(*'mp4v') #codec\n","      curpath =os.getcwd()\n","      out = cv2.VideoWriter(curpath+'detected_output.mp4', fourcc, 30.0, res)\n","      frame = None\n","      device = 'cuda'\n","      detection_threshold = 0.7\n","      while True:\n","          try:\n","              is_success, image_np = cap.read()\n","          except cv2.error:\n","              continue\n","\n","          if not is_success:\n","              break\n","\n","          # Actual detection.\n","          with torch.no_grad():\n","           boxes, classes, labels ,scores = run_inference_for_single_image(model, image_np, live_cam,device,detection_threshold)\n","          \n","          # Visualization of the results of a detection.\n","          # draw boxes and show current frame on screen\n","          image =draw_boxes(boxes, classes, labels, frame ,scores)\n","               \n","          out.write(image)\n","\n","      out.release() \n","\n","      # OPTIONAL: show last image\n","      if frame:\n","        cv2_imshow(frame)\n","\n","  cap.release()\n","\n","\n","\n","#Load model\n","model = LitDrinksModel.load_from_checkpoint('./weights/mymodel.ckpt')\n","model.eval().to('cuda')\n","detection_threshold = 0.7\n","\n"],"metadata":{"id":"Kvjf5ScoEg5p","executionInfo":{"status":"ok","timestamp":1651427743033,"user_tz":-480,"elapsed":1028,"user":{"displayName":"Abby Abby","userId":"18409237732645261754"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["# Video Demo"],"metadata":{"id":"2eO1vmspPTr7"}},{"cell_type":"code","source":["# start streaming video from webcam\n","video_stream()\n","# label for video\n","label_html = 'Capturing...'\n","# initialze bounding box to empty\n","bbox = None\n","count = 0 \n","device = 'cuda'\n","detection_threshold = 0.7\n","while True:\n","    js_reply = video_frame(label_html, bbox)\n","    if not js_reply:\n","        break\n","\n","    # convert JS response to OpenCV Image\n","    img = js_to_image(js_reply[\"img\"])\n","\n","     # Convert OpenCV BGR format to RGB format \n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","\n","    # Actual detection.\n","    with torch.no_grad():\n","      boxes, classes, labels ,scores = run_inference_for_single_image(model, img,True,device,detection_threshold)\n","      \n","      # Visualization of the results of a detection.\n","      # draw boxes and show current frame on screen\n","    image =draw_boxes(boxes, classes, labels, img ,scores)\n","        \n","\n","    # Convert OpenCV BGR format to RGB format \n","    #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    # Convert numpy image type to Base64 image byte string type\n","    # for JavaScript Video object \n","    bbox_bytes = bbox_to_bytes(image)\n","\n","    # update bbox so next frame gets new overlay\n","    bbox = bbox_bytes"],"metadata":{"id":"kdomgUhVOWQR","colab":{"resources":{"http://localhost:8080/None":{"data":"CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K","ok":false,"headers":[["content-length","1449"],["content-type","text/html; charset=utf-8"]],"status":404,"status_text":""}},"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1651427778294,"user_tz":-480,"elapsed":28234,"user":{"displayName":"Abby Abby","userId":"18409237732645261754"}},"outputId":"bf3a0ff9-eec8-47b6-a451-f8c94eee5b0e"},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    var video;\n","    var div = null;\n","    var stream;\n","    var captureCanvas;\n","    var imgElement;\n","    var labelElement;\n","    \n","    var pendingResolve = null;\n","    var shutdown = false;\n","    \n","    function removeDom() {\n","       stream.getVideoTracks()[0].stop();\n","       video.remove();\n","       div.remove();\n","       video = null;\n","       div = null;\n","       stream = null;\n","       imgElement = null;\n","       captureCanvas = null;\n","       labelElement = null;\n","    }\n","    \n","    function onAnimationFrame() {\n","      if (!shutdown) {\n","        window.requestAnimationFrame(onAnimationFrame);\n","      }\n","      if (pendingResolve) {\n","        var result = \"\";\n","        if (!shutdown) {\n","          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n","          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n","        }\n","        var lp = pendingResolve;\n","        pendingResolve = null;\n","        lp(result);\n","      }\n","    }\n","    \n","    async function createDom() {\n","      if (div !== null) {\n","        return stream;\n","      }\n","\n","      div = document.createElement('div');\n","      div.style.border = '2px solid black';\n","      div.style.padding = '3px';\n","      div.style.width = '100%';\n","      div.style.maxWidth = '600px';\n","      document.body.appendChild(div);\n","      \n","      const modelOut = document.createElement('div');\n","      modelOut.innerHTML = \"<span>Status:</span>\";\n","      labelElement = document.createElement('span');\n","      labelElement.innerText = 'No data';\n","      labelElement.style.fontWeight = 'bold';\n","      modelOut.appendChild(labelElement);\n","      div.appendChild(modelOut);\n","           \n","      video = document.createElement('video');\n","      video.style.display = 'block';\n","      video.width = div.clientWidth - 6;\n","      video.setAttribute('playsinline', '');\n","      video.onclick = () => { shutdown = true; };\n","      stream = await navigator.mediaDevices.getUserMedia(\n","          {video: { facingMode: \"environment\"}});\n","      div.appendChild(video);\n","\n","      imgElement = document.createElement('img');\n","      imgElement.style.position = 'absolute';\n","      imgElement.style.zIndex = 1;\n","      imgElement.onclick = () => { shutdown = true; };\n","      div.appendChild(imgElement);\n","      \n","      const instruction = document.createElement('div');\n","      instruction.innerHTML = \n","          '<span style=\"color: red; font-weight: bold;\">' +\n","          'When finished, click here or on the video to stop this demo</span>';\n","      div.appendChild(instruction);\n","      instruction.onclick = () => { shutdown = true; };\n","      \n","      video.srcObject = stream;\n","      await video.play();\n","\n","      captureCanvas = document.createElement('canvas');\n","      captureCanvas.width = 640; //video.videoWidth;\n","      captureCanvas.height = 480; //video.videoHeight;\n","      window.requestAnimationFrame(onAnimationFrame);\n","      \n","      return stream;\n","    }\n","    async function stream_frame(label, imgData) {\n","      if (shutdown) {\n","        removeDom();\n","        shutdown = false;\n","        return '';\n","      }\n","\n","      var preCreate = Date.now();\n","      stream = await createDom();\n","      \n","      var preShow = Date.now();\n","      if (label != \"\") {\n","        labelElement.innerHTML = label;\n","      }\n","            \n","      if (imgData != \"\") {\n","        var videoRect = video.getClientRects()[0];\n","        imgElement.style.top = videoRect.top + \"px\";\n","        imgElement.style.left = videoRect.left + \"px\";\n","        imgElement.style.width = videoRect.width + \"px\";\n","        imgElement.style.height = videoRect.height + \"px\";\n","        imgElement.src = imgData;\n","      }\n","      \n","      var preCapture = Date.now();\n","      var result = await new Promise(function(resolve, reject) {\n","        pendingResolve = resolve;\n","      });\n","      shutdown = false;\n","      \n","      return {'create': preShow - preCreate, \n","              'show': preCapture - preShow, \n","              'capture': Date.now() - preCapture,\n","              'img': result};\n","    }\n","    "]},"metadata":{}}]},{"cell_type":"code","source":[""],"metadata":{"id":"XdmHQGKkRKpW"},"execution_count":null,"outputs":[]}]}